{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# import re\n",
    "# import json\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import random\n",
    "from numpy import NaN as nan\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# father and son relationship \n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "# all_links = []\n",
    "links = []\n",
    "ref = 'https://www.imdb.com/search/keyword/?keywords=father-son-relationship&pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=bdc91cb7-0144-4906-b072-b45760c8aa67&pf_rd_r=7Z3ZH5FX7XE2AWRFJDEE&pf_rd_s=right-1&pf_rd_t=15051&pf_rd_i=genre&ref_=kw_nxt&mode=detail&'\n",
    "prod = '&title_type=movie&sort=user_rating,desc'\n",
    "for i in range(70,81,1):\n",
    "    time.sleep(random.uniform(2,4))\n",
    "    url = ref + 'page=' + str(i) + prod\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    divs = soup.find('div', {'class':'lister-list'}).find_all('div', {'class':'lister-item mode-detail'})\n",
    "    for div in divs:\n",
    "        a = div.find('a').get('href')\n",
    "        links.append(a)\n",
    "#     all_links.append(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_all_links = pd.DataFrame([])\n",
    "all_links_ser = pd.Series(a)\n",
    "len_list = range(0,len(all_links_ser))\n",
    "link = 'https://www.imdb.com'\n",
    "\n",
    "for i in links:\n",
    "#     data_for_some_links = pd.DataFrame([])\n",
    "#     for j in i:\n",
    "#         print(j)\n",
    "    url = link + i\n",
    "    print(url)\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "    try:\n",
    "        data_for_dir = soup.find('div', {'class':'credit_summary_item'})\n",
    "        a = data_for_dir.find('a')\n",
    "        director = list(a)[0]\n",
    "    except AttributeError:\n",
    "        director = nan\n",
    "    except IndexError:\n",
    "        director = nan\n",
    "\n",
    "    # жанры\n",
    "    try:\n",
    "        div = soup.find('div', {'id':'titleStoryLine'}).contents[19]\n",
    "        gen = div.find_all('a')\n",
    "        genres = []\n",
    "        for i in gen:\n",
    "            genres.append(i.string)\n",
    "    except AttributeError:\n",
    "        genres = nan\n",
    "    except IndexError:\n",
    "        genres = nan\n",
    "\n",
    "    # сценарист\n",
    "    try:\n",
    "        div = soup.find('div', {'class':'plot_summary'}).contents[5]\n",
    "        gen = div.find_all('a')\n",
    "        writer = list(gen[0])[0]\n",
    "    #     writers = []\n",
    "    #     for i in gen:\n",
    "    #         writers.append(i.text)\n",
    "    except AttributeError:\n",
    "        writer = nan\n",
    "    except IndexError:\n",
    "        writer = nan\n",
    "\n",
    "    # название    \n",
    "    try:\n",
    "        name = soup.find('div', {'class':'originalTitle'}).text\n",
    "    except AttributeError:\n",
    "        name = nan\n",
    "    except IndexError:\n",
    "        name = nan    \n",
    "\n",
    "    # дата релиза\n",
    "    try:\n",
    "        div = soup.find('div', {'id':'titleDetails'})\n",
    "        gen = div.find_all('div', {'class':'txt-block'})\n",
    "        data = []\n",
    "        for i in gen:\n",
    "            a = i.contents[2]\n",
    "            data.append(a)\n",
    "        date_release = data[3]\n",
    "    except AttributeError:\n",
    "        date_release = nan\n",
    "    except IndexError:\n",
    "        date_release = nan\n",
    "\n",
    "    # бюджет\n",
    "    try:\n",
    "        div = soup.find('div', {'id':'titleDetails'})\n",
    "        gen = div.find_all('div', {'class':'txt-block'})\n",
    "        data = []\n",
    "        for i in gen:\n",
    "            a = i.contents[2]\n",
    "            data.append(a)\n",
    "        budget = data[6]\n",
    "    except AttributeError:\n",
    "        budget = nan\n",
    "    except IndexError:\n",
    "        budget = nan    \n",
    "\n",
    "    # кассовые сборы в первую неделю (в сша)    \n",
    "    try:\n",
    "        div = soup.find('div', {'id':'titleDetails'})\n",
    "        gen = div.find_all('div', {'class':'txt-block'})\n",
    "        data = []\n",
    "        for i in gen:\n",
    "            a = i.contents[2]\n",
    "            data.append(a)\n",
    "        opening_weekend_usa = data[7]\n",
    "    except AttributeError:\n",
    "        opening_weekend_usa = nan\n",
    "    except IndexError:\n",
    "        opening_weekend_usa = nan\n",
    "\n",
    "    # кассовые сборы в сша    \n",
    "    try:\n",
    "        div = soup.find('div', {'id':'titleDetails'})\n",
    "        gen = div.find_all('div', {'class':'txt-block'})\n",
    "        data = []\n",
    "        for i in gen:\n",
    "            a = i.contents[2]\n",
    "            data.append(a)\n",
    "        gross_usa = data[8]\n",
    "    except AttributeError:\n",
    "        gross_usa = nan\n",
    "    except IndexError:\n",
    "        gross_usa = nan    \n",
    "\n",
    "    # кассовые сборы в мире\n",
    "    try:\n",
    "        div = soup.find('div', {'id':'titleDetails'})\n",
    "        gen = div.find_all('div', {'class':'txt-block'})\n",
    "        data = []\n",
    "        for i in gen:\n",
    "            a = i.contents[2]\n",
    "            data.append(a)\n",
    "        cumulative_worldwide_gross = data[9]\n",
    "    except AttributeError:\n",
    "        cumulative_worldwide_gross = nan\n",
    "    except IndexError:\n",
    "        cumulative_worldwide_gross = nan    \n",
    "\n",
    "\n",
    "    # страна производства\n",
    "    try:\n",
    "        div = soup.find('div', {'id':'titleDetails'})\n",
    "        gen = div.find_all('div', {'class':'txt-block'})\n",
    "        data = []\n",
    "        for i in gen:\n",
    "            a = i.find_all('a')\n",
    "            data.append(a)\n",
    "        country = list(data[1][0])[0]\n",
    "    except AttributeError:\n",
    "        country = nan\n",
    "    except IndexError:\n",
    "        country = nan\n",
    "\n",
    "    # компания производства\n",
    "    try:\n",
    "        production_co = soup.find('div', {'id':'titleDetails'}).contents[37].contents[3].contents[0]\n",
    "    except IndexError:\n",
    "        production_co = nan\n",
    "    except AttributeError:\n",
    "        production_co = nan\n",
    "\n",
    "\n",
    "    # описание (синопсис)\n",
    "    try:\n",
    "        div = soup.find('div', {'id':'titleStoryLine'})\n",
    "        gen = div.find_all('div', {'class':'inline canwrap'})\n",
    "        data = []\n",
    "        for i in gen:\n",
    "            a = i.find_all('span')\n",
    "            data.append(a)\n",
    "        description = list(data[0][0])[0]\n",
    "    except IndexError:\n",
    "        description = nan\n",
    "    except AttributeError:\n",
    "        description = nan\n",
    "\n",
    "    # длительность\n",
    "    try:\n",
    "        divs = soup.find('div', {'class':'title_wrapper'}) # для длительности фильма\n",
    "        run_time = divs.contents[5].contents[3].contents[0]\n",
    "        # div = divs.find('time', {'datetime':'PT125M'})\n",
    "        # run_time = div.contents[0].string\n",
    "    except IndexError:\n",
    "        run_time = nan\n",
    "    except AttributeError:\n",
    "        run_time = nan\n",
    "\n",
    "\n",
    "    # возрастной рейтинг\n",
    "    try:\n",
    "        divs = soup.find('div', {'class':'title_wrapper'}) # для возрастного рейтинга\n",
    "        div = divs.find('div', {'class':'subtext'})\n",
    "        age_rating = div.contents[0]\n",
    "    except IndexError:\n",
    "        age_rating = nan\n",
    "    except AttributeError:\n",
    "        age_rating = nan\n",
    "\n",
    "\n",
    "    # метаскоре\n",
    "    try:\n",
    "        div = soup.find('div', {'class':'titleReviewBarItem'}) # для метаскора (узнать, что такое метаскор)\n",
    "        meta = div.find_all('span')\n",
    "        list_for_meta = []\n",
    "        for i in meta:\n",
    "            list_for_meta.append(i.string)\n",
    "        metascore = list_for_meta[0]\n",
    "    except IndexError:\n",
    "        metascore = nan\n",
    "    except AttributeError:\n",
    "        metascore = nan\n",
    "\n",
    "    # рейтинг IMdb\n",
    "    try:\n",
    "        div = soup.find('div', {'class':'imdbRating'}) # рейтинг IMdb, кол-во отзывов и крит. рецензий\n",
    "        imdb_rat = div.find_all('span')\n",
    "        list_for_imdb_rat = []\n",
    "        for i in imdb_rat:\n",
    "            list_for_imdb_rat.append(i.string)\n",
    "        imdb_rating = list_for_imdb_rat[0]\n",
    "    except IndexError:\n",
    "        imdb_rating = nan\n",
    "    except AttributeError:\n",
    "        imdb_rating = nan\n",
    "\n",
    "\n",
    "    # количество проголосовавших\n",
    "    try:\n",
    "        div = soup.find('div', {'class':'imdbRating'}) # рейтинг IMdb, кол-во отзывов и крит. рецензий\n",
    "        imdb_rat = div.find_all('span')\n",
    "        list_for_imdb_rat = []\n",
    "        for i in imdb_rat:\n",
    "            list_for_imdb_rat.append(i.string)\n",
    "        all_who_put_rating = list_for_imdb_rat[3]\n",
    "    except IndexError:\n",
    "        all_who_put_rating = nan\n",
    "    except AttributeError:\n",
    "        all_who_put_rating = nan    \n",
    "\n",
    "    # количество тех, кто оставил отзыв\n",
    "    try:\n",
    "        div = soup.find('div', {'class':'imdbRating'}) # рейтинг IMdb, кол-во отзывов и крит. рецензий\n",
    "        imdb_rat = div.find_all('span')\n",
    "        list_for_imdb_rat = []\n",
    "        for i in imdb_rat:\n",
    "            list_for_imdb_rat.append(i.string)\n",
    "        all_users_who_put_rewiew = list_for_imdb_rat[4]\n",
    "    except IndexError:\n",
    "        all_users_who_put_rewiew = nan\n",
    "    except AttributeError:\n",
    "        all_users_who_put_rewiew = nan\n",
    "\n",
    "\n",
    "    # количество критиков, оставивших отзыв\n",
    "    try:\n",
    "        div = soup.find('div', {'class':'imdbRating'}) # рейтинг IMdb, кол-во отзывов и крит. рецензий\n",
    "        imdb_rat = div.find_all('span')\n",
    "        list_for_imdb_rat = []\n",
    "        for i in imdb_rat:\n",
    "            list_for_imdb_rat.append(i.string)\n",
    "        all_critics_who_put_rewiew = list_for_imdb_rat[5]\n",
    "    except IndexError:\n",
    "        all_critics_who_put_rewiew = nan\n",
    "    except AttributeError:\n",
    "        all_critics_who_put_rewiew = nan\n",
    "\n",
    "    # div = soup.find('div', {'class':'titleReviewBarItem titleReviewbarItemBorder'})\n",
    "    # crit = div.find_all('a')\n",
    "    # list_for_crit = []\n",
    "    # for i in crit:\n",
    "    #     print(i)\n",
    "    #     list_for_crit.append(i.string)\n",
    "    # all_new_users = list_for_crit[0]\n",
    "    # all_new_critic = list_for_crit[1]\n",
    "\n",
    "\n",
    "    data = (\n",
    "        [name, director,writer,\n",
    "         date_release, country, opening_weekend_usa, budget, gross_usa, \n",
    "         cumulative_worldwide_gross, production_co, \n",
    "         run_time, description,age_rating,\n",
    "         metascore, all_users_who_put_rewiew,\n",
    "         all_critics_who_put_rewiew, imdb_rating, all_who_put_rating\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    col = (\n",
    "        ['Name','Director','Writer','Date_release', \n",
    "         'Country',\n",
    "         'Opening_week_usa',\n",
    "         'Budget', 'Gross',\n",
    "         'Cum_world_gross','Production_co',\n",
    "         'Run_time','Description',\n",
    "         'Age_rating',\n",
    "         'Metascore','Number_of_rewiews',\n",
    "         'Number_of_critics','Imdb_rating','Number_of_who_rated']\n",
    "    )\n",
    "\n",
    "    total_data = (\n",
    "    (pd.DataFrame(\n",
    "    data,col\n",
    "    )).transpose()\n",
    "    )\n",
    "\n",
    "    print(total_data)\n",
    "\n",
    "    data_for_all_links = data_for_all_links.append(total_data)\n",
    "    data_for_some_links = (data_for_all_links.append(total_data)).drop_duplicates()\n",
    "\n",
    "    data_for_all_links.to_excel('C:/Users/1/Documents/Project/Data/father_and_son_3.xlsx', index = False)\n",
    "\n",
    "#         total_data = total_data.append(total_data)\n",
    "\n",
    "#         data_for_some_links = (data_for_some_links.append(total_data)).drop_duplicates()\n",
    "\n",
    "#     data_for_all_links = data_for_all_links.append(data_for_some_links)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
